{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-60)  var2(t-60)  var3(t-60)  var1(t-59)  var2(t-59)  var3(t-59)  \\\n",
      "271    0.000000    0.882353     0.00000    0.000000    0.823530     0.03125   \n",
      "272    0.000000    0.823530     0.03125    0.333333    0.647059     0.06250   \n",
      "273    0.333333    0.647059     0.06250    0.333333    0.647059     0.09375   \n",
      "274    0.333333    0.647059     0.09375    0.000000    0.823530     0.06875   \n",
      "275    0.000000    0.823530     0.06875    0.000000    0.823530     0.06875   \n",
      "\n",
      "     var1(t-58)  var2(t-58)  var3(t-58)  var1(t-57)  ...  var1(t-3)  \\\n",
      "271    0.333333    0.647059     0.06250    0.333333  ...   0.033333   \n",
      "272    0.333333    0.647059     0.09375    0.000000  ...   0.033333   \n",
      "273    0.000000    0.823530     0.06875    0.000000  ...   0.033333   \n",
      "274    0.000000    0.823530     0.06875    0.000000  ...   0.033333   \n",
      "275    0.000000    0.823530     0.08750    0.000000  ...   0.033333   \n",
      "\n",
      "     var2(t-3)  var3(t-3)  var1(t-2)  var2(t-2)  var3(t-2)  var1(t-1)  \\\n",
      "271   0.882353    0.48125   0.033333    0.82353    0.48125   0.033333   \n",
      "272   0.823530    0.48125   0.033333    0.82353    0.48125   0.033333   \n",
      "273   0.823530    0.48125   0.033333    0.82353    0.50000   0.033333   \n",
      "274   0.823530    0.50000   0.033333    0.82353    0.51875   0.033333   \n",
      "275   0.823530    0.51875   0.033333    0.82353    0.51875   0.033333   \n",
      "\n",
      "     var2(t-1)  var3(t-1)  var3(t)  \n",
      "271    0.82353    0.48125  0.50000  \n",
      "272    0.82353    0.50000  0.51875  \n",
      "273    0.82353    0.51875  0.51875  \n",
      "274    0.82353    0.51875  0.50000  \n",
      "275    0.82353    0.50000  0.50000  \n",
      "\n",
      "[5 rows x 181 columns]\n",
      "(1533, 60, 3) (1533,) (294, 60, 3) (294,)\n",
      "10/10 [==============================] - 0s 776us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m test_X \u001b[39m=\u001b[39m test_X\u001b[39m.\u001b[39mreshape((test_X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], n_obs))\n\u001b[0;32m     84\u001b[0m \u001b[39m# invert scaling for forecast\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m inv_yhat \u001b[39m=\u001b[39m concatenate((test_X[:, [\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m]], yhat), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     86\u001b[0m inv_yhat \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39minverse_transform(inv_yhat)\n\u001b[0;32m     87\u001b[0m inv_yhat \u001b[39m=\u001b[39m inv_yhat[:, \u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "# load dataset\n",
    "col_list = [\"H2S\", \"PH\", \"Temp\"]\n",
    "dataset = read_csv('DATASET_2019.csv',usecols=col_list)\n",
    "dataset = dataset[[\"H2S\", \"PH\", \"Temp\"]]\n",
    "values = dataset.values\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_hours = 60\n",
    "n_features = 3\n",
    "n_obs = n_hours * n_features\n",
    "# frame as supervised learning\n",
    "# reframed = series_to_supervised(values, n_hours , 1)\n",
    "reframed = series_to_supervised(scaled, n_hours , 1)\n",
    "reframed.drop(reframed.columns[[n_obs,(n_obs+1)]], axis=1, inplace=True)\n",
    "print(reframed.head())\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = int(len(dataset) * 0.7)\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "\n",
    "train_X, train_y = train[:, :n_obs], train[:, -1]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -1]\n",
    "# print(train_X.shape, len(train_X), train_y.shape)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "# make a prediction\n",
    "model = Sequential()\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], n_obs))\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((test_X[:, [0,1]], yhat), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:, 2]\n",
    "\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_X[:, [0,1]], test_y), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,2]\n",
    "\n",
    "# calculate RMSE\n",
    "mse = mean_squared_error(inv_y, inv_yhat)\n",
    "rmse = sqrt(mse)\n",
    "print('Test MSE: %.3f' % mse)\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "lose_model = abs(inv_y-inv_yhat)\n",
    "lose_model = lose_model.reshape(-1,1)\n",
    "#print(lose_model.shape)\n",
    "mean = np.mean(lose_model)\n",
    "min = np.amin(lose_model) \n",
    "max = np.amax(lose_model) \n",
    "range = np.ptp(lose_model) \n",
    "varience = np.var(lose_model) \n",
    "sd = np.std(lose_model) \n",
    "print(\"Measures of Dispersion\")\n",
    "print(\"Mean =\", mean)\n",
    "print(\"Minimum =\", min) \n",
    "print(\"Maximum =\", max) \n",
    "print(\"Range =\", range) \n",
    "print(\"Varience =\", varience) \n",
    "print(\"Standard Deviation =\", sd)\n",
    "# Visualising the results\n",
    "pyplot.figure(figsize=(14,5))\n",
    "pyplot.plot(inv_y, color = 'red', label = 'actual')\n",
    "pyplot.plot(inv_yhat, color = 'blue', label = 'predict by multi params')\n",
    "pyplot.xlabel('Sampling Point', fontsize=15)\n",
    "pyplot.ylabel('Temperature', fontsize=15)\n",
    "pyplot.legend()\n",
    "pyplot.savefig(\"temperature_multi_params.svg\", format = 'svg', dpi=300)\n",
    "pyplot.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov  4 2022, 16:35:55) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6c0ba649dbe20eb25d8caa371f9be91aaac62735d4e5cecc3028d83f4a29e16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
